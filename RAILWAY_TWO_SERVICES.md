# Deploying Two Services to Railway from One Repo

## Your Question: How Does Railway Know What to Run?

**Great question!** Here's how it works:

### The Answer: Railway Service Settings Override Git Files

When you override settings in Railway dashboard, Railway stores them **in its own database**, NOT in your Git repo.

**Your Git Repo:**
- `railway.json` â†’ `"startCommand": "python job_server.py"` âœ…
- `Procfile` â†’ `web: python job_server.py` and `worker: python scheduled_scraper.py` âœ…
- These files **never change** when you configure Railway

**Railway's Database:**
- Service 1 (API): Uses default â†’ `python job_server.py`
- Service 2 (Scraper): Uses override â†’ `python scheduled_scraper.py`
- **Railway remembers** these settings forever

---

## Two Ways to Deploy Both Services

### Method 1: Using Procfile Process Types (RECOMMENDED)

Your `Procfile` defines two process types:
```
web: python job_server.py
worker: python scheduled_scraper.py
```

**Deploy with Railway:**

1. **First Service (API) - Automatic:**
   - Railway auto-deploys from GitHub
   - Uses `web` process from Procfile
   - Runs: `python job_server.py` âœ…

2. **Second Service (Scraper) - Manual Setup:**
   - In Railway, click **"+ New"** â†’ **"Empty Service"**
   - In service settings:
     - **Source**: Same GitHub repo
     - **Root Directory**: Leave empty
     - **Start Command**: `python scheduled_scraper.py`
   - Add same environment variables
   - Deploy!

### Method 2: Manual Override (Alternative)

**Deploy Both:**
1. Create first service from GitHub (API)
2. Create second service from same GitHub repo
3. Override start command in Railway dashboard

**How Railway Remembers:**
- Railway stores override in its service configuration
- Every redeploy uses the stored settings
- Your Git repo stays clean âœ…

---

## Step-by-Step: Deploy Both Services (EASY METHOD)

### Service 1: API Server

**Already deployed!** Railway automatically:
- âœ… Detects `railway.json`
- âœ… Runs `python job_server.py`
- âœ… Serves API on assigned PORT

### Service 2: Auto-Scraper

1. **In Railway dashboard**, click **"+ New"**

2. **Select "GitHub Repo"**
   - Choose: `job-aggregation-api`
   - Railway creates new service

3. **Configure the Service:**
   - Click on the new service card
   - Go to **"Settings"** tab
   - Scroll to **"Deploy"** section
   - **Root Directory**: Leave empty
   - **Start Command**: Enter `python scheduled_scraper.py`
   - **Build Command**: Leave as default
   - Click **"Save"**

4. **Add Environment Variables:**
   - Go to **"Variables"** tab
   - Add the same variables as API service:
     ```
     DATABASE_URL=postgresql://neondb_owner:...
     RAPIDAPI_KEY=55a6230b03mshd0f690b6b6ec590p12fc6bjsnbea6f9f1be9b
     RAPIDAPI_INDEED_HOST=indeed-jobs-api.p.rapidapi.com
     ```

5. **Deploy:**
   - Service will auto-deploy
   - Check **"Logs"** tab to see it start scraping!

---

## How Railway Tracks This

### In Railway's Database:

```
Project: job-aggregation-api
â”œâ”€â”€ Service 1: "api-service"
â”‚   â”œâ”€â”€ Git Repo: mfish324/job-aggregation-api
â”‚   â”œâ”€â”€ Start Command: (default from railway.json)
â”‚   â””â”€â”€ Runs: python job_server.py
â”‚
â””â”€â”€ Service 2: "scraper-service"
    â”œâ”€â”€ Git Repo: mfish324/job-aggregation-api (same repo!)
    â”œâ”€â”€ Start Command: python scheduled_scraper.py (OVERRIDE)
    â””â”€â”€ Runs: python scheduled_scraper.py
```

### In Your Git Repo (Unchanged):

```
GitHub: mfish324/job-aggregation-api
â”œâ”€â”€ railway.json â”€â”€â†’ "startCommand": "python job_server.py"
â”œâ”€â”€ Procfile â”€â”€â”€â”€â”€â”€â†’ web: python job_server.py
â”‚                    worker: python scheduled_scraper.py
â””â”€â”€ (No changes when you configure Railway!)
```

---

## Future Deployments

**When you push to GitHub:**

```bash
git add .
git commit -m "Update job filters"
git push origin main
```

**Railway automatically:**
1. âœ… Detects push
2. âœ… Redeploys **both services**
3. âœ… Service 1: Uses `python job_server.py` (from railway.json)
4. âœ… Service 2: Uses `python scheduled_scraper.py` (from Railway override)
5. âœ… Both services restart with latest code

**Your overrides are permanent** until you change them in Railway!

---

## Why This Works

### Railway's Service Model:

Each service has:
- **Code Source**: Your GitHub repo
- **Service Settings**: Stored in Railway's database
- **Override Priority**: Railway settings > Procfile > railway.json

### Settings Hierarchy:

```
1. Manual Override in Railway Dashboard (HIGHEST)
   â†“
2. Procfile process type
   â†“
3. railway.json startCommand
   â†“
4. Railway auto-detection (LOWEST)
```

So when you override in Railway dashboard, it **always** uses that, even after redeployments!

---

## Example: After You Configure

### First Deploy:
```bash
git push origin main
```

**Railway Action:**
- Service 1: Runs `python job_server.py` âœ…
- Service 2: Runs `python scheduled_scraper.py` âœ…

### Second Deploy (1 week later):
```bash
git add new_feature.py
git commit -m "Add new feature"
git push origin main
```

**Railway Action:**
- Service 1: Runs `python job_server.py` âœ… (still remembers!)
- Service 2: Runs `python scheduled_scraper.py` âœ… (still remembers!)

**No manual configuration needed!** Railway remembers forever.

---

## Monitoring Both Services

### In Railway Dashboard:

**Service 1 (API):**
- Logs show: `INFO: Application startup complete.`
- Metrics show: HTTP requests coming in
- Health check: `https://your-api.up.railway.app/health`

**Service 2 (Scraper):**
- Logs show: `Searching remoteok for 'junior developer'`
- Metrics show: Steady CPU usage
- No public URL (background worker)

---

## Summary

**Your Concern:** "If I override Railway settings, how does it remember?"

**Answer:**
âœ… Railway stores overrides in **its own database**
âœ… Your Git repo **never changes**
âœ… Future deployments **remember the override**
âœ… Each service has **independent configuration**

**The Process:**
1. Deploy Service 1 â†’ Uses `railway.json` or `Procfile`
2. Deploy Service 2 â†’ Override start command in Railway
3. Railway remembers both configurations
4. Every future `git push` uses remembered settings
5. âœ¨ No manual work needed!

**Your Git repo stays clean, Railway tracks the differences!** ðŸŽ‰

---

## Quick Reference

### Service 1 (API):
- **What**: Job aggregation REST API
- **Start**: `python job_server.py`
- **Config**: Automatic (from `railway.json`)
- **URL**: `https://your-app.up.railway.app`

### Service 2 (Scraper):
- **What**: Auto-scraper finding jobs 24/7
- **Start**: `python scheduled_scraper.py`
- **Config**: Manual override in Railway
- **URL**: None (background worker)

### Both Services:
- **Repo**: Same (`job-aggregation-api`)
- **Database**: Same (Neon PostgreSQL)
- **Variables**: Same (DATABASE_URL, etc.)
- **Deploy**: Automatic on `git push`

You're all set! Deploy the second service and both will run 24/7! ðŸš€
